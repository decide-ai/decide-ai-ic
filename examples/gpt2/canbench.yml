manifest_version: "1"
name: "gpt2-model-benchmarks"
canister_name: model
canister_id: "dccg7-xmaaa-aaaaa-qaamq-cai"

build_cmd: >-
    RUSTFLAGS="$RUSTFLAGS -C target-feature=+simd128" cargo build --release --target wasm32-wasi --features canbench-rs && 
    wasi2ic ./target/wasm32-wasi/release/model.wasm ./target/wasm32-wasi/release/model-ic.wasm &&
    wasm-opt -Os -o ./target/wasm32-wasi/release/model-ic.wasm ./target/wasm32-wasi/release/model-ic.wasm

wasm_path: ./target/wasm32-wasi/release/model-ic.wasm

candid_path: "src/model/model.did"

# Network configuration
network:
  type: "local"
  url: "http://127.0.0.1:4943"

# Setup steps with verification
setup:
  - method: "load_tokenizer_bytes_from_stable"
    args: []
    verify: true
  - method: "setup_tokenizer"
    args: []
    verify: true
  - method: "load_safetensors_bytes_from_stable"
    args: []
    verify: true
  - method: "append_config_bytes"
    args: ["~/.cache/huggingface/hub/models--vicgalle--gpt2-open-instruct-v1/snapshots/eccf4d5899c24523625fe3d41f1cf78c755821b0/config.json"]
    verify: true
  - method: "setup_model"
    args: []
    verify: true

pre_benchmark_verification:
  method: "model_state_check"
  args: []

# Benchmark definitions
benchmarks:
  # Tokenizer benchmarks
  tokenizer_borrow:
    method: "benchmark_tokenizer_borrow"
    cycles_limit: 100000000000
    memory_limit: 2000000000
    args: []

  tokenizer_access:
    method: "benchmark_tokenizer_access"
    cycles_limit: 100000000000
    memory_limit: 2000000000
    args: []

  encode_small:
    method: "benchmark_encode_small"
    cycles_limit: 100000000000
    memory_limit: 2000000000
    args: []

  vector_conversion:
    method: "benchmark_vector_conversion"
    cycles_limit: 100000000000
    memory_limit: 2000000000
    args: []

  error_handling:
    method: "benchmark_error_handling"
    cycles_limit: 100000000000
    memory_limit: 2000000000
    args: []

  tokenizer_small_full:
    method: "benchmark_tokenizer_small_full"
    cycles_limit: 100000000000
    memory_limit: 2000000000
    args: []

  tokenizer_small:
    method: "benchmark_tokenizer_small"
    cycles_limit: 100000000000
    memory_limit: 2000000000
    args: []

  tokenizer_large:
    method: "benchmark_tokenizer_large"
    cycles_limit: 100000000000
    memory_limit: 2000000000
    args: []

  # Model state and inference
  model_state:
    method: "model_state_check"
    cycles_limit: 100000000000
    memory_limit: 2000000000
    args: []

  inference:
    method: "inference_with_state_check"
    cycles_limit: 200000000000
    memory_limit: 4000000000
    args: []

  # Fibonacci benchmarks
  fib_base:
    method: "fibonacci_base_case"
    cycles_limit: 100000000000
    memory_limit: 1000000000
    args: []

  fib_20:
    method: "fibonacci_20"
    cycles_limit: 100000000000
    memory_limit: 1000000000
    args: []

  fib_45:
    method: "fibonacci_45"
    cycles_limit: 100000000000
    memory_limit: 1000000000
    args: []

  fib_loop_20:
    method: "fibonacci_loop_20"
    cycles_limit: 100000000000
    memory_limit: 1000000000
    args: []

  fib_loop_45:
    method: "fibonacci_loop_45"
    cycles_limit: 100000000000
    memory_limit: 1000000000
    args: []

  # Memory benchmarks
  large_alloc:
    method: "benchmark_large_allocation"
    cycles_limit: 100000000000
    memory_limit: 5000000000
    args: []

  retained_alloc:
    method: "benchmark_retained_allocation"
    cycles_limit: 100000000000
    memory_limit: 1000000000
    args: []

  string_alloc:
    method: "benchmark_string_allocation"
    cycles_limit: 100000000000
    memory_limit: 4000000000
    args: []